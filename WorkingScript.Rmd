---
title: "Working script"
output: pdf_document
date: "2025-11-04"
---



```{r}
library(dplyr)
library(glmnet)
library(Metrics)
library(tidymodels)

# For testing
data_2025 <- read.csv("Data/2025baseballdata.csv")

# For training
data_2024 <- read.csv("Data/2024bbdata.csv")
data_2023 <- read.csv("Data/2023bbdata.csv")
data_2022 <- read.csv("Data/2022bbdata.csv")
data_2021 <- read.csv("Data/2021bbdata.csv")
data_2020 <- read.csv("Data/2020bbdata.csv")

data_2020 <- data_2020 |> select(-c("Awards", "Pos", "Team", "Lg") )
data_2021 <- data_2021 |> select(-c("Awards", "Pos", "Team", "Lg") )
data_2022 <- data_2022 |> select(-c("Awards", "Pos", "Team", "Lg") )
data_2023 <- data_2023 |> select(-c("Awards", "Pos", "Team", "Lg") )
data_2024 <- data_2024 |> select(-c("Awards", "Pos", "Team", "Lg") )

data_2020$year <- 2020
data_2021$year <- 2021
data_2022$year <- 2022
data_2023$year <- 2023
data_2024$year <- 2024

training_data <- rbind(data_2024, data_2023, data_2022, data_2021, data_2020)

training_data <- training_data |> 
  arrange(Player, year ) |>
  group_by(Player) |>
  mutate(WAR_next = lead(WAR, 1)) |>
  ungroup()

training_data <- training_data |> filter(!is.na(WAR_next))

training_clean <- training_data |> select(-c("Player", "year", "WAR_next"))

ols_spec <- linear_reg() |>
  set_engine("lm")

ols_fit <- ols_spec |>
  fit(WAR ~ ., data = training_clean)

summary(ols_fit$fit)

set.seed(445)
data_split <- initial_split(training_clean, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)

ols_fit <- ols_spec |>
  fit(WAR ~., data = train)

preds <- predict(ols_fit, test) |> bind_cols(test)

rmse(preds, truth = WAR, estimate = .pred)
mae(preds, truth = WAR, estimate = .pred)
```

```{r}
training_data <- training_data |>
  arrange(Player, year) |>
  group_by(Player) |>
  mutate(WAR_next = lead(WAR,1),
         WAR_next = ifelse(is.na(WAR_next), mean(WAR), WAR_next) ) |>
  ungroup()

# LASSO
lasso_spec <- linear_reg(mixture = 1, penalty = tune() ) |> set_mode("regression") |> set_engine("glmnet")

lasso_kfold <- vfold_cv(train, v = 10)

lambda_grid <- tibble(penalty = 10^seq(-2, 10, length.out = 100) )

lasso_recipe <- recipe(WAR ~ ., data = train)

lasso_flow <- workflow() |>
  add_model(lasso_spec) |>
  add_recipe(lasso_recipe) 

lasso_fit <- lasso_flow |>
  tune_grid(resamples = lasso_kfold, grid = lambda_grid)

best_lasso <- select_best(lasso_fit, metric = "rmse")

lasso_final <- finalize_workflow(lasso_flow, best_lasso)

lasso_final_fit <- lasso_final |> fit(train)

lasso_preds_train <- lasso_final_fit |> augment(train)
lasso_preds_test <- lasso_final_fit |> augment(test)

```

```{r}
lasso_rmse_train <- rmse(lasso_preds_train, truth = WAR, estimate = .pred)$.estimate
lasso_mae_train <- mae(lasso_preds_train, truth = WAR, estimate = .pred)$.estimate

lasso_rmse_test <- rmse(lasso_preds_test, truth = WAR, estimate = .pred)$.estimate
lasso_mae_test <- mae(lasso_preds_test, truth = WAR, estimate = .pred)$.estimate

non_zero <- lasso_final_fit |> extract_fit_parsnip()|> tidy() |> filter(term != "(Intercept)" & estimate != 0) |> nrow()
zero <- lasso_final_fit |> extract_fit_parsnip()|> tidy() |> filter(term != "(Intercept)" & estimate == 0) |> nrow()

lasso_metrics <- data.frame(train_rmse = lasso_rmse_train ,test_rmse = lasso_rmse_test, 
                            train_mae = lasso_mae_train, test_mae = lasso_mae_test, 
                            non_zero = non_zero, shrunk_coefs = zero) 
lasso_metrics
```




```{r}
library(xgboost)
library(tidymodels)

set.seed(445)

boost_folds <- vfold_cv(train, v = 10)

boost_recipe <- recipe(WAR ~ ., data = train)

boost_spec <- boost_tree(
  trees          = 500,
  tree_depth     = tune(),
  learn_rate     = tune(),
  min_n          = tune(),
  loss_reduction = 0,
  sample_size    = 1
) |>
  set_mode("regression") |>
  set_engine("xgboost")


boost_grid <- grid_random(
  tree_depth(),
  learn_rate(),
  min_n(),
  size = 20
)


boost_flow <- workflow() |> add_model(boost_spec) |> add_recipe(boost_recipe)
```

```{r}
boost_tuned <- boost_flow |>
tune_grid(
resamples = boost_folds,
grid = boost_grid,
metrics = metric_set(rmse, mae)
)


best_boost <- select_best(boost_tuned, metric = "rmse")
best_boost

```

```{r}
boost_final <- finalize_workflow(boost_flow, best_boost)

boost_final_fit <- boost_final |> fit(data = train)

boost_preds_train <- augment(boost_final_fit, train)
boost_preds_test <- augment(boost_final_fit, test)

head(boost_preds_test)
```

```{r}

boost_rmse_train <- rmse(boost_preds_train, truth = WAR, estimate = .pred)$.estimate
boost_mae_train <- mae(boost_preds_train, truth = WAR, estimate = .pred)$.estimate


boost_rmse_test <- rmse(boost_preds_test, truth = WAR, estimate = .pred)$.estimate
boost_mae_test <- mae(boost_preds_test, truth = WAR, estimate = .pred)$.estimate

boost_metrics <- data.frame(
train_rmse = boost_rmse_train,
test_rmse = boost_rmse_test,
train_mae = boost_mae_train,
test_mae = boost_mae_test
)

boost_metrics
```

