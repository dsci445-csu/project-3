---
title: "Working script"
output: pdf_document
date: "2025-11-04"
---



```{r}
library(dplyr)
library(glmnet)
library(Metrics)
library(tidymodels)

# For testing
data_2025 <- read.csv("Data/2025baseballdata.csv")
data_2025 <- data_2025 |> select(-c("Awards", "Pos", "Team", "Lg", "Player","Rk"))

# For training
data_2024 <- read.csv("Data/2024bbdata.csv")
data_2023 <- read.csv("Data/2023bbdata.csv")
data_2022 <- read.csv("Data/2022bbdata.csv")
data_2021 <- read.csv("Data/2021bbdata.csv")
data_2020 <- read.csv("Data/2020bbdata.csv")

data_2020 <- data_2020 |> select(-c("Awards", "Pos", "Team", "Lg","Rk") )
data_2021 <- data_2021 |> select(-c("Awards", "Pos", "Team", "Lg","Rk") )
data_2022 <- data_2022 |> select(-c("Awards", "Pos", "Team", "Lg","Rk") )
data_2023 <- data_2023 |> select(-c("Awards", "Pos", "Team", "Lg","Rk") )
data_2024 <- data_2024 |> select(-c("Awards", "Pos", "Team", "Lg","Rk") )

data_2020$year <- 2020
data_2021$year <- 2021
data_2022$year <- 2022
data_2023$year <- 2023
data_2024$year <- 2024

training_data <- rbind(data_2024, data_2023, data_2022, data_2021, data_2020)

training_data <- training_data |>
  arrange(Player, year) |>
  group_by(Player) |>
  mutate(WAR_next = lead(WAR,1),
         WAR_next = ifelse(is.na(WAR_next), mean(WAR), WAR_next) ) |>
  ungroup()

training_data <- training_data |> dplyr::filter(!is.na(WAR_next))

training_clean <- training_data |> select(-c("Player", "year", "WAR_next"))

```


```{r}
ols_spec <- linear_reg() |>
  set_engine("lm")

ols_fit <- ols_spec |>
  fit(WAR ~ ., data = training_clean)

summary(ols_fit$fit)

set.seed(445)
data_split <- initial_split(training_clean, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)

ols_fit <- ols_spec |>
  fit(WAR ~., data = train)

preds <- predict(ols_fit, test) |> bind_cols(test)

yardstick::rmse(preds, truth = WAR, estimate = .pred)
yardstick::mae(preds, truth = WAR, estimate = .pred)


```

```{r}
ols_preds_train <- predict(ols_fit, train) |> bind_cols(train)
ols_preds_test <- preds

ols_rmse_train <- yardstick::rmse(ols_preds_train, truth = WAR, estimate = .pred)$.estimate
ols_mae_train  <- yardstick::mae(ols_preds_train,  truth = WAR, estimate = .pred)$.estimate

ols_rmse_test <- yardstick::rmse(ols_preds_test, truth = WAR, estimate = .pred)$.estimate
ols_mae_test  <- yardstick::mae(ols_preds_test,  truth = WAR, estimate = .pred)$.estimate

ols_metrics <- data.frame(
  train_rmse = ols_rmse_train,
  test_rmse = ols_rmse_test,
  train_mae = ols_mae_train,
  test_mae = ols_mae_test
)

ols_metrics
```

```{r}

# LASSO
lasso_spec <- linear_reg(mixture = 1, penalty = tune() ) |> set_mode("regression") |> set_engine("glmnet")

lasso_kfold <- vfold_cv(train, v = 10)

lambda_grid <- tibble(penalty = 10^seq(-2, 10, length.out = 100) )

lasso_recipe <- recipe(WAR ~ ., data = train)

lasso_flow <- workflow() |>
  add_model(lasso_spec) |>
  add_recipe(lasso_recipe) 

lasso_fit <- lasso_flow |>
  tune_grid(resamples = lasso_kfold, grid = lambda_grid)

best_lasso <- select_best(lasso_fit, metric = "rmse")

lasso_final <- finalize_workflow(lasso_flow, best_lasso)

lasso_final_fit <- lasso_final |> fit(train)

lasso_preds_train <- lasso_final_fit |> augment(train)
lasso_preds_test <- lasso_final_fit |> augment(test)

```

```{r}
lasso_rmse_train <- yardstick::rmse(lasso_preds_train, truth = WAR, estimate = .pred)$.estimate
lasso_mae_train <- yardstick::mae(lasso_preds_train, truth = WAR, estimate = .pred)$.estimate

lasso_rmse_test <- yardstick::rmse(lasso_preds_test, truth = WAR, estimate = .pred)$.estimate
lasso_mae_test <- yardstick::mae(lasso_preds_test, truth = WAR, estimate = .pred)$.estimate

non_zero <- lasso_final_fit |> extract_fit_parsnip()|> tidy() |> filter(term != "(Intercept)" & estimate != 0) |> nrow()
zero <- lasso_final_fit |> extract_fit_parsnip()|> tidy() |> filter(term != "(Intercept)" & estimate == 0) |> nrow()

lasso_metrics <- data.frame(train_rmse = lasso_rmse_train ,test_rmse = lasso_rmse_test, 
                            train_mae = lasso_mae_train, test_mae = lasso_mae_test, 
                            non_zero = non_zero, shrunk_coefs = zero) 
lasso_metrics
```


```{r}
boost_tuned <- boost_flow |>
tune_grid(
resamples = boost_folds,
grid = boost_grid,
boost_tuned <- boost_flow |>
  tune_grid(
    resamples = boost_folds,
    grid      = boost_grid,
    metrics   = metric_set(yardstick::rmse, yardstick::mae)
  )

)


best_boost <- select_best(boost_tuned, metric = "rmse")
best_boost

```

```{r}
boost_final <- finalize_workflow(boost_flow, best_boost)

boost_final_fit <- boost_final |> fit(data = train)

boost_preds_train <- augment(boost_final_fit, train)
boost_preds_test <- augment(boost_final_fit, test)

head(boost_preds_test)
```

```{r}

boost_rmse_train <- yardstick::rmse(boost_preds_train, truth = WAR, estimate = .pred)$.estimate
boost_mae_train <- yardstick::mae(boost_preds_train, truth = WAR, estimate = .pred)$.estimate


boost_rmse_test <- yardstick::rmse(boost_preds_test, truth = WAR, estimate = .pred)$.estimate
boost_mae_test <- yardstick::mae(boost_preds_test, truth = WAR, estimate = .pred)$.estimate

boost_metrics <- data.frame(
train_rmse = boost_rmse_train,
test_rmse = boost_rmse_test,
train_mae = boost_mae_train,
test_mae = boost_mae_test
)

boost_metrics
```

```{r}
#TESTING

#OLS
ols_preds_2025 <- predict(ols_fit, data_2025) |> bind_cols(data_2025)

#LASSO
lasso_preds_2025 <- lasso_final_fit |> augment(data_2025)

#BOOSTING
boost_preds_2025 <- augment(boost_final_fit, data_2025)

```


```{r}
library(ggplot2)

ggplot(boost_preds_2025, aes(x = WAR, y = .pred)) +
  geom_point(alpha = 0.6, color = "#59A14F", size = 3) +
  geom_abline(slope = 1, intercept = 0, 
              color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "Boosting Model: Actual vs Predicted WAR (2025 Data)",
    x = "Actual WAR",
    y = "Predicted WAR"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    panel.grid.minor = element_blank()
  )

```

```{r}
library(ggplot2)

ggplot(ols_preds_2025, aes(x = WAR, y = .pred)) +
  geom_point(alpha = 0.6, color = "4E79A7" , size = 3)+
  geom_abline(slope = 1, interecpt = 0, 
              color = "red" , linetype = "dashed" , linewidth = 1) +
  labs(
    title =  "OLS Model: Actual vs Predicted WAR (2025 Data)" , 
    x = "Actual WAR" ,
    y = "Predicted WAR"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold" , hjust = 0.5),
    panel.grid.minor = element_blank()
  )

ggsave(
  filename = "Pictures/OLS_comp_plot.png",
  plot = last_plot(),
  width = 8,
  height = 5,
  dpi = 300
)
```

```{r}
ggplot(lasso_preds_2025, aes(x = WAR, y = .pred)) +
  geom_point(alpha = 0.6, color = "#F28E2B", size = 3) +
  geom_abline(slope = 1, intercept = 0,
              color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "LASSO Model: Actual vs Predicted WAR (2025 Data)",
    x = "Actual WAR",
    y = "Predicted WAR"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    panel.grid.minor = element_blank()
  )
```

```{r}
library(yardstick)
#Computing RMSE and MAE 2025 data 
# OLS
ols_rmse_2025 <- yardstick::rmse(ols_preds_2025, truth = WAR, estimate = .pred)$.estimate
ols_mae_2025  <- yardstick::mae(ols_preds_2025,  truth = WAR, estimate = .pred)$.estimate

# LASSO
lasso_rmse_2025 <- yardstick::rmse(lasso_preds_2025, truth = WAR, estimate = .pred)$.estimate
lasso_mae_2025  <- yardstick::mae(lasso_preds_2025,  truth = WAR, estimate = .pred)$.estimate

# BOOSTING
boost_rmse_2025 <- yardstick::rmse(boost_preds_2025, truth = WAR, estimate = .pred)$.estimate
boost_mae_2025  <- yardstick::mae(boost_preds_2025,  truth = WAR, estimate = .pred)$.estimate

```



```{r}
library(dplyr)
library(ggplot2)

rmse_results_2025 <- tibble(
  model = c("OLS", "LASSO", "Boosting"),
  rmse  = c(ols_rmse_2025,
            lasso_rmse_2025,
            boost_rmse_2025)
)

ggplot(rmse_results_2025, aes(x = model, y = rmse, fill = model)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(rmse, 3)),
            vjust = -0.5,
            size = 5) +
  expand_limits(y = max(rmse_results_2025$rmse) + 0.1) +
  labs(
    title = "Model Comparison on 2025 Data: RMSE",
    x = "Model",
    y = "Root Mean Squared Error (RMSE)"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none") +
  scale_fill_manual(values = c(
    "OLS" = "#4E79A7",
    "LASSO" = "#F28E2B",
    "Boosting" = "#59A14F"
  ))


```

```{r}
library(dplyr)
library(ggplot2)

mae_results_2025 <- tibble(
  model = c("OLS", "LASSO", "Boosting"),
  mae   = c(ols_mae_2025,
            lasso_mae_2025,
            boost_mae_2025)
)

ggplot(mae_results_2025, aes(x = model, y = mae, fill = model)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(mae, 3)), 
            vjust = -0.5, size = 5) +
  expand_limits(y = max(mae_results_2025$mae) + 0.1) +
  labs(
    title = "Model Comparison on 2025 Data: MAE",
    x = "Model",
    y = "Mean Absolute Error (MAE)"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none") +
  scale_fill_manual(values = c(
    "OLS" = "#4E79A7",
    "LASSO" = "#F28E2B",
    "Boosting" = "#59A14F"
  ))


```

```{r}
library(yardstick)

# OLS
ols_r2_2025 <- rsq(ols_preds_2025, truth = WAR, estimate = .pred)$.estimate

# LASSO
lasso_r2_2025 <- rsq(lasso_preds_2025, truth = WAR, estimate = .pred)$.estimate

# BOOSTING
boost_r2_2025 <- rsq(boost_preds_2025, truth = WAR, estimate = .pred)$.estimate

```

```{r}
r2_results_2025 <- tibble(
  model = c("OLS", "LASSO", "Boosting"),
  r2    = c(ols_r2_2025,
            lasso_r2_2025,
            boost_r2_2025)
)


ggplot(r2_results_2025, aes(x = model, y = r2, fill = model)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(r2, 3)),
            vjust = -0.5, size = 5) +
  expand_limits(y = max(r2_results_2025$r2) + 0.05) +
  labs(
    title = "Model Comparison on 2025 Data: R²",
    x = "Model",
    y = "R-Squared (R²)"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none") +
  scale_fill_manual(values = c(
    "OLS" = "#4E79A7",
    "LASSO" = "#F28E2B",
    "Boosting" = "#59A14F"
  ))
```

```{r}
ols_preds_2025 <- predict(ols_fit, data_2025) |> bind_cols(data_2025)
ols_rmse_2025 <- yardstick::rmse(ols_preds_2025, truth = WAR, estimate = .pred)$.estimate


ols_rmse_2025 <- yardstick::rmse(ols_preds_2025, truth = WAR, estimate = .pred)$.estimate
ols_mae_2025  <- yardstick::mae(ols_preds_2025,  truth = WAR, estimate = .pred)$.estimate

ols_rmse_2025
ols_mae_2025

ols_metrics <- data.frame(
  dataset = c("Train", "Test", "2025"),
  RMSE = c(ols_rmse_train, ols_rmse_test, ols_rmse_2025),
  MAE = c(ols_mae_train, ols_mae_test, ols_mae_2025)
)

ols_metrics_long <- ols_metrics |>
  pivot_longer(cols = c(RMSE, MAE),
               names_to = "Metric",
               values_to = "Value")


ggplot(ols_metrics_long, aes(x = dataset, y = Value, fill = Metric)) +
       geom_col(position = "dodge") + 
         labs(
           title = "OLS Model Error Comparison",
           x = "Dataset",
           y = "Value",
           fill = "Metric"
         ) +
         theme_minimal()
```
```{r}
lasso_metrics_pres <- data.frame(
  dataset = c("Train", "Test", "2025"),
  RMSE = c(lasso_rmse_train, lasso_rmse_test, lasso_rmse_2025),
  MAE = c(lasso_mae_train, lasso_mae_test, lasso_mae_2025)
)

lasso_metrics_long <- lasso_metrics_pres |>
  pivot_longer(cols = c(RMSE, MAE),
               names_to = "Metric",
               values_to = "Value")


ggplot(lasso_metrics_long, aes(x = dataset, y = Value, fill = Metric)) +
       geom_col(position = "dodge") + 
       geom_text(aes(label = round(Value, digits = 3)), color =  "black", vjust = 5,
                 size = 6, position = position_dodge(width = 0.9)) +
         labs(
           title = "LASSO Model Error Comparison",
           x = "Dataset",
           y = "Value",
           fill = "Metric"
         ) +
  scale_fill_manual(values = c("RMSE" = "lightblue", "MAE" = "forestgreen")) +
  theme_minimal()
 


```
```{r}
boost_metrics_pres <- data.frame(
  dataset = c("Train", "Test", "2025"),
  RMSE = c(boost_rmse_train, boost_rmse_test, boost_rmse_2025),
  MAE = c(boost_mae_train, boost_mae_test, boost_mae_2025)
)

boost_metrics_long <- boost_metrics_pres |>
  pivot_longer(cols = c(RMSE, MAE),
               names_to = "Metric",
               values_to = "Value")


ggplot(boost_metrics_long, aes(x = dataset, y = Value, fill = Metric)) +
       geom_col(position = "dodge") + 
       geom_text(aes(label = round(Value, digits = 3)), color =  "darkgray", vjust = 5,
                 size = 6, position = position_dodge(width = 0.9)) +
         labs(
           title = "Boosting Model Error Comparison",
           x = "Dataset",
           y = "Value",
           fill = "Metric"
         ) +
  scale_fill_manual(values = c("RMSE" = "navy", "MAE" = "#556B2E")) +
  theme_minimal()
 
```
```{r}
players_2025 <- read.csv("Data/2025baseballdata.csv")
players <- players_2025 |> select(c("Rk", "Player"))


judge <- data_2025 |> filter(WAR == 9.7 & PA == 679)
goodman <- data_2025 |> filter(WAR == 3.7 & PA == 579)
toglia <- data_2025 |> filter(WAR == -1.7 & PA == 337)
witt <- data_2025 |> filter(WAR == 7.1 & PA == 687)


#players |> filter(Player == "Bobby Witt Jr.")
#tail(players_2025 |> arrange(desc(WAR)))

judge_preds <- augment(ols_fit, judge) 
judge_preds <- judge_preds |> select(c(".pred", "WAR"))

goodman_preds <- augment(ols_fit, goodman) 
goodman_preds <- goodman_preds |> select(c(".pred", "WAR"))

toglia_preds <- augment(ols_fit, toglia) 
toglia_preds <- toglia_preds |> select(c(".pred", "WAR"))

witt_preds <- augment(ols_fit, witt) 
witt_preds <- witt_preds |> select(c(".pred", "WAR"))

example_preds <- data.frame("Player" = c("Aaron Judge", "Hunter Goodman", "Michael Toglia", "Bobby Witt Jr."),
                            "Prediction" = c(judge_preds$.pred, goodman_preds$.pred, toglia_preds$.pred, witt_preds$.pred),
                            "Actual" = c(judge_preds$WAR, goodman_preds$WAR, toglia_preds$WAR, witt_preds$WAR ))
example_preds_nice <- example_preds |> kable()

example_preds_nice
```

